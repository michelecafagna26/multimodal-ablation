# VL-Ablation
*Official implementation of the **multimodal input ablation method** used in the paper: ["What Vision-Language Models 'See' when they See Scenes"](https://arxiv.org/abs/2109.07301).*

---
A tool to perform targeted semantic multimodal input ablation.

### Overview

- **üóÉÔ∏è Repository:** [github.com/michelecafagna26/vl-ablation](https://github.com/michelecafagna26/vl-ablation)
- **üìú Paper:** [What Vision-Language Models 'See' when they See Scenes](https://arxiv.org/abs/2109.07301)
- **üñäÔ∏è Contact:** michele.cafagna@um.edu.mt

### Requirements

```txt
pytorch
torchvision
```

### Installation

```bash
pip install git+https://github.com/michelecafagna26/vl-ablation.git#egg=ablation
```

# Quick Start
```python3
```

### Citation Information

```BibTeX
@article{cafagna2021vision,
  title={What Vision-Language ModelsSee'when they See Scenes},
  author={Cafagna, Michele and van Deemter, Kees and Gatt, Albert},
  journal={arXiv preprint arXiv:2109.07301},
  year={2021}
}
```
